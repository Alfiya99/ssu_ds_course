{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN practice.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Xeapf_vYGl80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.models import resnet34\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GpHmo0BG2SX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сегодня мы будем использовать transfer learning чтобы обучить классификатор героев классических звёздных войн. Эта практика требует обучения на GPU (иначе код будет выполнятся очень долго), поэтому используйте https://colab.research.google.com.\n",
        "\n",
        "Сначала нужно включить поддержку GPU. Зайдите в Edit -> Notebook settings и как hardware accelerator укажите GPU."
      ]
    },
    {
      "metadata": {
        "id": "K9HRimYvHWJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь нужно скачать данные, выполните следующую ячейку.\n",
        "В первый раз она попросит вас перейти по ссылке - откройте эту ссылку и скопируйте оттуда токен (длинную строку в base64), вставьте этот токен в окошко под ячейкой."
      ]
    },
    {
      "metadata": {
        "id": "glyFL0_dHknT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_data(file_id, file_name):\n",
        "  import io\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  downloaded = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(downloaded, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "    \n",
        "  downloaded.seek(0)\n",
        "  with open(file_name, \"wb\") as f:\n",
        "    f.write(downloaded.read())\n",
        "\n",
        "  \n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id = '139wA_Z9kustXy54ifhWWHJvARo5f7O6y'\n",
        "file_name = 'star_wars.tar.gz'\n",
        "\n",
        "download_data(file_id, file_name)\n",
        "!tar xf star_wars.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9msPyG3H_Rz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Важная часть обучения нейронных сетей (как и обычно в машинном обучении)  - это работа с данными. Необходимо представить данные в векторном виде и отдать их модели для обучения. В фреймворке Pytorch для этого используется связка двух классов: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset и https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader. Первый это даже не класс, а интерфейс - у него всего два интересных метода:\n",
        "__getitem__ - выбрать из датасета элемент по заданному числовому индексу\n",
        "__len__ - вернуть длину датасета.\n",
        "\n",
        "Как видите этот интерфейс эквивалентен обычному массиву. \n",
        "\n",
        "DataLoader в свою очередь занимается тем что выбирает элементы из Dataset который передается ему в конструкторе и делает из них батчи для обучения нейронной сети. Вы можете контролировать размер батча с помощью параметра batch_size, также не забудьте включать перемешивание данных перед каждой эпохой передавая в DataLoader параметр shuffle=True. В более продвинутых случаях возможно задавать стратегию того как именно конструируются батчи с помощью классов Sampler и BatchSampler, но мы в нашей практике этих возможностей касаться не будем.\n",
        "\n",
        "Главное отличие Dataset от массива на практике в том что этот интерфейс не обязывает вас хранить весь набор данных в памяти. Типичная реализация по индексу подгружает данные с диска и делает из них сэмпл. \n",
        "\n",
        "Для задачи классификации изображений не нужно писать свой DataLoader - вместо этого есть готовый из пакета torchvision: https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder \n",
        "Он требует следующей структуры файлов на диске:\n",
        "\n",
        "```\n",
        "root/dog/xxx.png\n",
        "root/dog/xxy.png\n",
        "root/dog/xxz.png\n",
        "\n",
        "root/cat/123.png\n",
        "root/cat/nsdf3.png\n",
        "root/cat/asd932_.png\n",
        "```\n",
        "\n",
        "Другими словами изображения должны быть сгруппированы по классам в папки с названиями своего класса."
      ]
    },
    {
      "metadata": {
        "id": "p__lNU_4Kqca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Попробуйте сейчас создать ImageFolder от папки star_wars которую мы сейчас скачали и вывести на экран первое изображение (это делается также как и с массивом: `data[0]`)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8Ny_q5lKs8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Изображение вывелось в полном размере. Мы собираемся использовать transfer learning - взять сеть предобученную на ImageNet и доучить её на наших изображениях. Сети тренировавшиеся на ImageNet требуют стандартного размера картинок: 224x224.\n",
        "Нам нужно поресайзить картинки. У ImageFolder для этого есть аргумент конструктора transform=. Опять, нам не нужно самим писать код приведения изображения к размеру 224x224. Для этого мы воспользуемся тем-же пакетом torchvision."
      ]
    },
    {
      "metadata": {
        "id": "mxdMrj_bLvR8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "augmentations = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yX6fprMHMBco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Здесь мы поресайзили изображение к размеру 224х224 и преобразовали его в тензор - многомерный массив, который можно далее дать на вход сети для обучения. Пересоздайте ImageFolder с данными трансформациями."
      ]
    },
    {
      "metadata": {
        "id": "PTDyOuAVMUnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Для оценки качества нам нужна тестовая выборка. Сейчас мы поступим просто - поделим все данные в соотношении 70/30.\n",
        "Чтобы это сделать можно воспользоваться классом Subset.\n",
        "Он оборачивает данный в конструкторе Dataset предоставляя доступ только к элементам по переданным индексам. Его идея суть как в этом коде:\n",
        "```\n",
        "array = [1, 2, 3, 4, 5]\n",
        "\n",
        "class Subset:\n",
        "    def __init__(self, array, indexes):\n",
        "         self.indexes = indexes\n",
        "         \n",
        "    def __len__(self):\n",
        "         return len(self.indexes)\n",
        "         \n",
        "    def __getitem__(self, i):\n",
        "         return array[self.indexes[i]]\n",
        "         \n",
        "         \n",
        " Subset(array, [0, 3, 4])[1] # Вернет 4\n",
        "```\n",
        "\n",
        "Поделите наш ImageFolder на train и test с помощью: \n",
        "- np.arange - чтобы сгенерировать индексы\n",
        "- train_test_split - чтобы выбрать подмножество индексов\n",
        "- Subset - чтобы выбрать подвыборку данных\n"
      ]
    },
    {
      "metadata": {
        "id": "dBJWD7TxQ36S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Разбейте data на train и test в соотношении 70/30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1QgZzKgRagH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Здесь мы берем предобученный resnet34 и заменяем в нём последний слой на голову классифицирующую изображение на 1 из 4 классов\n",
        "# Берём кросс энтропию в качестве лосса и оптимизатор адам\n",
        "# Мы замораживаем все слои сети кроме последнего, который будем обучать далее\n",
        "\n",
        "\n",
        "model = resnet34(pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 4)\n",
        "model.to('cuda')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tu_ihCt-RFtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = # создайте DataLoader от train с batch_size=256. Пошаффлите данные.\n",
        "test_loader = # создайте DataLoader от test с batch_size=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNNJdU2QRse4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Эта функция считает точность модели - на вход передается сама модель, номер эпохи и тестовый лоадер.\n",
        "\n",
        "def run_test_on_epoch(model, epoch, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_accuracy = []\n",
        "      test_real = []\n",
        "      for batch_x, batch_y in tqdm(test_loader):\n",
        "          outputs = model(batch_x.to('cuda')).detach().cpu().numpy()\n",
        "          test_accuracy.append(outputs)\n",
        "          test_real.append(batch_y.detach().cpu().numpy())\n",
        "      print(\"Epoch\", epoch, \"test accuracy\", accuracy_score(np.hstack(test_real), np.argmax(np.hstack(test_accuracy), axis=1)))\n",
        "    model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GY3ofh1SSAec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Напишите код для обучения модели 25 эпох. В конце каждой эпохи вызывайте run_test_on_epoch() чтобы следить за точностью"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zq093_VVSaBG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Повторите эксперимент выше после того как добавите несколько аугментаций из https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "То что стоит попробовать:\n",
        "- повороты изображения до 45 градусов\n",
        "- приведение в ЧБ\n",
        "- ??? (то что придумаете сами)"
      ]
    }
  ]
}