{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Лекция 3. Полносвязные нейронные сети__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__О чём эта лекция__\n",
    "\n",
    "- Что такое полносвязные нейронные сети\n",
    "- Как они выглядят\n",
    "- Каковы их возможности\n",
    "- Как их обучают\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Что такое нейрон?__\n",
    "\n",
    "$$ \\sigma(\\sum_{j=1}^{n} x^j w_j - w_0) $$\n",
    "\n",
    "$x^j$ - признаки, $w_j$ - веса признаков. $w_0$ - bias.  \n",
    "Аналогично линейной регрессии, обычно добавляют признак $x^0=-1$ и пишут $$ \\sigma(\\sum_{j=0}^{n} x^j w_j) $$\n",
    "![alt](neuron.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Что такое нейрон?__\n",
    "$$ \\sigma(\\sum_{j=0}^{n} x^j w_j) $$\n",
    "\n",
    "$\\sigma$ - функция активации. \n",
    "Если $ \\sigma (z) =  \\dfrac{1}{1+e^{-z}} $, то получаем логистическую регрессию.  \n",
    "Если $ \\sigma(z) = z $, то получаем линейную регрессию.\n",
    "\n",
    "Существует множество разных функций активации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Что может один нейрон?__\n",
    "\n",
    "Реализовать логическое \"И\" \n",
    "$$ x^1 \\land x^2 = x^1 + x^2 - 1.5 > 0 $$\n",
    "\n",
    "Реализовать логическое \"ИЛИ\"\n",
    "\n",
    "$$ x^1 \\lor x^2  = x^1 + x^2 - 0.5 > 0 $$\n",
    "\n",
    "Реализовать логическое \"НЕ\"\n",
    "\n",
    "$$ \\lnot x^1 = -x^1 + 0.5 > 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Что НЕ может один нейрон?__\n",
    "\n",
    "Реализовать XOR (исключающее или).\n",
    "\n",
    "Два способа решить это:\n",
    "\n",
    "- Добавление признака: $$ x^1 \\oplus x^2  = x^1 + x^2 - 2 x^1 x^2 -0.5 > 0$$\n",
    "- Добавление __слоя__: $$ x^1 \\oplus x^2  = (x^1 \\lor x^2) - (x^1 \\land x^2) -0.5 > 0 $$\n",
    "\n",
    "![](xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Нейронные сети как граф вычислений__\n",
    "\n",
    "Суперпозиция слоев:\n",
    "$$ x^1 \\oplus x^2 = (x^1 \\lor x^2) \\land {\\lnot (x^1 \\land x^2)} $$  \n",
    "\n",
    "где $\\land, \\lor, \\lnot$ - нейроны с предыдущих слайдов и функцией активации $sign$.\n",
    "\n",
    "* Нейронная сеть - граф вычислений (суперпозиция слоев - функций) над признаками. \n",
    "* Таким образом с ними работают в современных библиотеках (tensorflow, pytorch, keras...)\n",
    "\n",
    "* Это язык описания архитектур нейронных сетей\n",
    "\n",
    "Какие бывают архитектуры нейронных сетей?\n",
    "![](model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.layers import Layer, Input, Concatenate\n",
    "from keras import Model\n",
    "\n",
    "\n",
    "class And(Layer):\n",
    "    pass\n",
    "\n",
    "class Or(Layer):\n",
    "    pass\n",
    "\n",
    "class Not(Layer):\n",
    "    pass\n",
    "\n",
    "x=Input(shape=(2,), name='x')\n",
    "a_and_b=And(name='')(x)\n",
    "a_or_b=Or()(x)\n",
    "not_a = Not()(a_and_b)\n",
    "model = And()([a_or_b, not_a])\n",
    "plot_model(Model(inputs=x, outputs=model), show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Виды нейронных сетей__\n",
    "\n",
    "Существуют разные типы слоев (операций) и типы архитектур нейронных сетей:\n",
    "\n",
    "- полносвязные\n",
    "- сверточные\n",
    "- рекуррентные\n",
    "- рекурсивные\n",
    "\n",
    "При этом:\n",
    "\n",
    "- В сверточных сетях используются полносвязные слои\n",
    "- В рекуррентных сетях аналогично могут использоваться свертки\n",
    "- и так далее\n",
    "\n",
    "Почему?\n",
    "- Так происходит т.к. сеть - граф вычислений в котором могут встречаться разные операции\n",
    "\n",
    "Далее рассмотрим самый простой тип - полносвязные нейронные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Пример полносвязной нейронной сети__\n",
    "\n",
    "У полносвязной нейронной сети каждый нейрон текущего слоя связан с каждым нейроном предыдущего.\n",
    "\n",
    "Пример для двух слоев:\n",
    "\n",
    "![](fully_connected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Нейронные сети__\n",
    "\n",
    "Вопрос: Чем параметры модели отличаются от гиперпараметров?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Нейронные сети - параметры и гиперпараметры__\n",
    "\n",
    "Обучаемые параметры:\n",
    "- Веса сети - $w_{ij}$ - вес связи нейрона\\признака $i$ и нейрона $j$\n",
    "\n",
    "Гиперпараметры:\n",
    "- Архитектура сети\n",
    "   - Количество слоев\n",
    "   - Количество нейронов в слоях\n",
    "   - Используемые функции активации\n",
    "   - ...\n",
    "\n",
    "На практике встречаются исключения, например функции активации с обучаемыми параметрами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Нейронные сети - реальность__\n",
    "\n",
    "Что говорим:\n",
    "\n",
    "- Нейроны, связи, веса, активации...\n",
    "\n",
    "Что происходит _на самом деле_:\n",
    "\n",
    "- Матрицы умножаются на вектора и от них вычисляются нелинейные функции\n",
    "\n",
    "$$ \\sigma (\\sum w_{ji} x_{kj}) = \\sigma(W^T x) $$ \n",
    "\n",
    "Это причина почему нейронные сети обучают на GPU:\n",
    "- архитектура SIMD (single instruction multiple data) \n",
    "- можно быстро умножать матрицы и применять функции на векторы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Выразительная способность нейронных сетей__\n",
    "\n",
    "- Нейронная сеть с одним скрытым слоем может отделить в $R^n$ любой многогранник\n",
    "- Нейронная сеть с двумя скрытыми слоями может отделить в $R^n$ произвольную многогранную область\n",
    "    - возможно не связную\n",
    "    - возможно не выпуклую\n",
    "- Нейронной сетью с одним скрытым слоем и нелинейной функцией активации (предыдущий слайд) можно приблизить любую непрерывную функцию с наперед заданной точностью\n",
    "\n",
    "Таким образом нейронные сети являются универсальными аппроксиматорами. \n",
    "- Теоретически двух-трёх слоев достаточно\n",
    "- На практике часто используют глубокие нейронные сети для встроенного обучения признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Функции активации__\n",
    "\n",
    "- На практике применяют разные функции активации\n",
    "- Обычно стараются применять дифференциируемые почти везде (кроме конечного количества точек)\n",
    "\n",
    "Очень часто используются:\n",
    " -  $ \\sigma(x) = \\dfrac{1}{1+e^{-x}}$ сигмоида, например, на выходе для задачи бинарной классификации\n",
    " - $ softmax(x_j) = \\dfrac{e^{x_j}}{\\sum_{i}{e^{x_i}}} $ - софтмакс, чаще всего на выходе для задачи с несколькими непересекающимися классами\n",
    " \n",
    " ![](sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Функции активации__\n",
    "\n",
    "$ tanh(x) $ - гиперболический тангенс, ранее предлагался как альтернатива $\\sigma(x)$ на скрытых слоях сети\n",
    "\n",
    "![](Tanh.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Функции активации__\n",
    "\n",
    "$ ReLU(x) = max(x, 0) $ - REctified Linear Unit, широко используется сейчас для скрытых слоёв сетей\n",
    "\n",
    "<img src=\"relu.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Обучение нейронных сетей__\n",
    "\n",
    "- Как-правило для обучения сети требуется довольно большая выборка\n",
    "- Функция потерь нейронной сети на практике не выпуклая\n",
    "\n",
    "Поэтому для обучения нейронных сетей сейчас применяют вариации метода стохастического градиентного спуска (как правило с использованием mini-batch).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Обучение нейронных сетей__\n",
    "\n",
    "Проблема:\n",
    "\n",
    "На каждом шаге стохастического градиентного спуска нужно вычислить градиент ошибки. Как это сделать эффективно?\n",
    "\n",
    "Решение:\n",
    "\n",
    "Метод обратного распространения ошибки (Backprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "Пример:\n",
    "- Полносвязная нейронная сеть с одним скрытым слоем (которую мы рассматривали некоторое время назад)\n",
    "- Выходной слой $$a_m(x) = \\sigma_{m} (\\sum_\\limits{h=0}^{H}{w_{hm} u_{h}(x)}) $$\n",
    "Здесь $w_{hm}$ - вес связи нейрона h скрытого слоя и нейрона m выходного слоя\n",
    "- Скрытый слой $$ u_h(x) = \\sigma_{h} (\\sum_\\limits{j=0}^{n}{w_{jh} x^j}) $$\n",
    "Здесь также $w_{jh}$ - вес связи признака $x^j$ примера $x$ и нейрона h скрытого слоя\n",
    "- Среднеквадратичная функция потерь\n",
    "$$ SE(x, y) = \\dfrac{1}{2} \\sum_\\limits{m=1}^{M} (a_{m}(x) - y_{m})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__ \n",
    "\n",
    "\n",
    "Задача:\n",
    "- Найти градиент - вектор производных по параметрам модели\n",
    "\n",
    "Вопрос залу:\n",
    "\n",
    "- Что за параметры?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "Нужно найти $\\nabla SE(w) = < \\dfrac{\\partial SE(w)}{d w_{ij}} > $ как функции от весов сети.\n",
    "\n",
    "Найдем сначала производные по нейронам выходного и скрытого слоя:\n",
    "$ \\dfrac{\\partial SE(w)}{d a_{m}} $ и $\\dfrac{\\partial SE(w)}{d u_{h}} $.\n",
    "\n",
    "$$ \\dfrac{\\partial SE(w)}{d a_{m}}  = \\dfrac{\\partial \\dfrac{1}{2} \\sum_\\limits{m=1}^{M} (a_{m}(w) - y_{m})^2}{d a_{m}} = a_m (w) - y_m = \\epsilon_m $$ \n",
    "\n",
    "$\\epsilon_m$ - значение производной выше, ошибка модели на выходном слое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "\n",
    "Посмотрим на ошибку модели на скрытом слое:\n",
    "- Правило дифф. сложной функции:\n",
    "$$\\dfrac{\\partial SE(w)}{d u_{h}} = \\sum_\\limits{m=1}^{M} \\dfrac{\\partial SE}{d a_m} \\dfrac{\\partial a_m}{d u_h} = $$\n",
    "- Подстановка известного значения производной по $a_m$:\n",
    "$$= \\sum_\\limits{m=1}^{M} \\epsilon_m \\dfrac{\\partial a_m}{d u_h} = $$\n",
    "- По определению $a_m(x)$:\n",
    "$$= \\sum_\\limits{m=1}^{M} \\epsilon_m \\dfrac{\\partial \\sigma_{m} (\\sum_\\limits{h=0}^{H}{w_{hm} u_{h}(x)})}{d u_h} = $$\n",
    "\n",
    "Вопрос:\n",
    "\n",
    "Что делаем дальше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "... продолжаем искать производную ошибки на скрытом слое: \n",
    "\n",
    "- Правило дифф. сложной функции, второй раз:\n",
    "$$= \\sum_\\limits{m=1}^{M} \\epsilon_m \\sigma_m' \\dfrac{\\partial \\sum_\\limits{h=0}^{H}{w_{hm} u_{h}(x)}}{d u_h} = $$\n",
    "- Результат:\n",
    "$$= \\sum_\\limits{m=1}^{M} \\epsilon_m \\sigma_m' w_{hm}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "- Результат:\n",
    "$$\\dfrac{\\partial SE(w)}{d u_{h}} = \\sum_\\limits{m=1}^{M} \\epsilon_m \\sigma_m' w_{hm} = \\epsilon_h$$\n",
    "![](backprop.png)\n",
    "Наблюдения:\n",
    " - значение производной можно получить запустив сеть \"наоборот\"\n",
    " - вычисление производной суть последовательное применение правила дифф. сложной функции над компонентами сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "Наблюдения:\n",
    " - значение производной можно получить запустив сеть \"наоборот\"\n",
    " - вычисление производной суть последовательное применение правила дифф. сложной функции над компонентами сети:\n",
    "    - слоями\n",
    "    - функциями активаций\n",
    "\n",
    "Подтверждение:\n",
    "$$\\dfrac{\\partial SE}{d w_{hm}}  = \\dfrac{\\partial SE}{d a_m} \\dfrac{\\partial a_m}{d w_{hm}} = \\epsilon_m \\sigma_m' u_h(x)$$\n",
    "\n",
    "$$\\dfrac{\\partial SE}{d w_{jh}}  = \\dfrac{\\partial SE}{d a_m} \\dfrac{\\partial a_m}{d w_{jh}} = \\epsilon_m \\dfrac{\\partial a_m}{d u_h} \\dfrac{\\partial u_h}{d w_{jh}} = \\epsilon_m \\epsilon_h \\sigma_h' x^j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки__\n",
    "\n",
    "- Прямой ход:\n",
    "    - Применить слой за слоем на данный пример, посчитать значение функции потерь от выходов\n",
    "- Обратный ход:\n",
    "    - Считать значения производных слой за слоем в обратном направлении от выходов к входам\n",
    "        - Используя правило дифференцирования сложной функции\n",
    "        - Считать сначала производные ошибки от выходов, затем производные ошибки от последнего скрытого слоя и т.д. пока не будут расчитаны производные по всем весам\n",
    "\n",
    "Посчитаный градиент использовать для расчета шага в стохастическом градиентном спуске."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки на графе__\n",
    "\n",
    "Сейчас для работы с нейронными сетями активно используют идею графа вычислений.\n",
    "В графе есть следующие вершины:\n",
    " - Параметры модели (веса)\n",
    " - Входы (пример из обучающей выборки)\n",
    " - Операции (функции активации, умножение матрицы на вектор...)\n",
    "\n",
    "Прямой ход: \n",
    "\n",
    "- Вычисление значение функции ошибки по графу от входов к вершине - функции ошибки\n",
    "\n",
    "Обратный ход:\n",
    "\n",
    "- Вычисление производных ошибки для всех вершин графа в обратном порядке (от ошибки ко входам)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки на графе__\n",
    "\n",
    "![](autodiff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки на графе__\n",
    "\n",
    "\n",
    "Дано:\n",
    "- Некоторый граф вычислений (как на предыдущем слайде)\n",
    "- Значения входов, весов (и прочих параметров)\n",
    "\n",
    "Вопрос:\n",
    "- Что нужно знать о каждой вершине графа чтобы уметь применить на нём алгоритм обратного распространения ошибки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Алгоритм обратного распространения ошибки на графе__\n",
    "\n",
    "По сути для каждой вершины нужно знать:\n",
    "* как по входам вычислить её значение (прямой ход)\n",
    "* как посчитать её градиент от выходов (обратный ход)\n",
    "\n",
    "Таким образом построение нейронных сетей превращается из упражнений по дифференцированию и матричной алгебре в описание графов вычислений из заданных компонент (вершин). Обычно предоставляются:\n",
    "- автоматическое дифференцирование графов - алгоритм обратного распространения ошибки\n",
    "- набор компонент для построения сетей (слои, функции активации...)\n",
    "- набор оптимизаторов для обучения\n",
    "\n",
    "Далее поговорим подробнее об обучении и борьбе с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Momentum__\n",
    "\n",
    "Существует приличное множество модификаций стохастического градиентного спуска, все из которых используются на практике при обучении сетей:\n",
    "- Обычный градиентный шаг ` x+= -learning_rate * dx`\n",
    "\n",
    "- Momentum - экспоненциальное скользящее среднее по $\\approx \\dfrac{1}{1-\\gamma}$ итерациям спуска:\n",
    "```\n",
    "v = mu * v - learning_rate * dx # накапливаем скорость\n",
    "x += v # меняем позицию\n",
    "```\n",
    "- Nesterov momentum:\n",
    "```\n",
    "v_prev = v # сохраняем старое значение скорости\n",
    "v = mu * v - learning_rate * dx # накапливаем скорость\n",
    "x += -mu * v_prev + (1 + mu) * v # обновляем позицию от точки \"x - mu * v_prev\" вместо x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Momentum__\n",
    "- Физическая аналогия для этих эвристик - накопление импульса при спуске (шар с ненулевой массой)\n",
    "    \n",
    "![](momentum.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Методы с адаптивной скоростью обучения__ \n",
    "\n",
    "- Adagrad:\n",
    "```\n",
    "# dx - градиент, x - вектор параметров\n",
    "cache += dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```\n",
    "   - Скорость обучения своя под каждый параметр:\n",
    "       - Большая производная от параметра - скорость обучения падает\n",
    "       - Маленькая производная - скорость обучения растет\n",
    "- RMSProp:\n",
    "```\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```\n",
    "   - decay_rate - гиперпараметр с типичными значениями 0.9, 0.99, 0.999\n",
    "   - В отличие от Adagrad обновления скорости обучения не монотонны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Методы с адаптивной скоростью обучения__ \n",
    "\n",
    "- Adam - сейчас чаще всего используется на практике\n",
    "```\n",
    "# t - номер итерации \n",
    "m = beta1*m + (1-beta1)*dx\n",
    "mt = m / (1-beta1**t)\n",
    "v = beta2*v + (1-beta2)*(dx**2)\n",
    "vt = v / (1-beta2**t)\n",
    "x += - learning_rate * mt / (np.sqrt(vt) + eps)\n",
    "```\n",
    "    - Напоминает комбинацию RMSProp и Nesterov momentum\n",
    "    - Рекомендуемые значения гиперпараметров `eps = 1e-8`, `beta1 = 0.9`, `beta2 = 0.999`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Визуализация сходимости методов__\n",
    "![](optimizers.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Визуализация сходимости методов__\n",
    "\n",
    "Наблюдение:\n",
    "Несмотря на то что это всего-лишь эвристики, они обладают большим влиянием на скорость сходимости спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Dropout__\n",
    "\n",
    "Идея:\n",
    " - Во время обучения (но не применения!) будем случайным образом \"выключать\" нейроны\n",
    " \n",
    "Мотивы:  \n",
    "- получаем приближение ансамбля из $2^N$ сетей с общими весами, но разными связями между нейронами\n",
    "- тренируем сеть наиболее устойчивую к утрате нейронов надеясь что она будет надежной\n",
    "- заставляем разные части сети решать одну и ту-же задачу, а не компенсировать ошибки других частей\n",
    "\n",
    "Результат:\n",
    "\n",
    "Отличный метод борбы с переобучением нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Инициализация весов__\n",
    "\n",
    "Как __не надо__ делать:\n",
    " - инициализация нулями (эффективно погасит градиенты)\n",
    "\n",
    "Для неглубоких сетей (2-5 слоев):\n",
    " - инициализация небольшими случайными значениями около нуля\n",
    "\n",
    "Для глубоких сетей применяют спец. методы исходящие из статистических соображений:\n",
    "- Для симметричных функций активации с нулевым средним:\n",
    "    - инициализация Ксавье \n",
    " \n",
    "- Для ReLU, sigmoid и подобных несиммметричных функций:\n",
    "    - Инициализация Хе\n",
    "- Batch normalisation - нормализация выходов слоев (до активации) по мини-батчам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Заключение__\n",
    "\n",
    "- Нейронные сети - универсальный аппроксиматор\n",
    "- На практике сейчас их описывают на языке графов вычислений\n",
    "- Нейронные сети обычно обучаются вариациями стохастического градиентного спуска\n",
    "    - градиент вычисляют методом обратного распространения ошибки\n",
    "- Существует очень большое количество эвристик связанных с обучением нейронных сетей\n",
    "    - Много модификаций алгоритма стохастического градиентного спуска\n",
    "    - Дополнительные методы регуляризации (dropout)\n",
    "    - Специальные методы инициализации весов"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
